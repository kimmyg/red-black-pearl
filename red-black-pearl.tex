\documentclass[preprint]{sigplanconf}

% The following \documentclass options may be useful:
%
% 10pt          To set in 10-point type instead of 9-point.
% 11pt          To set in 11-point type instead of 9-point.
% authoryear    To obtain author/year citation style instead of numeric.

\usepackage{amsmath}

\begin{document}

\conferenceinfo{ICFP '13}{date, Boston} 
\copyrightyear{2013} 
\copyrightdata{[to be supplied]} 

\titlebanner{Red-Black Tree Deletion}        % These are ignored unless
\preprintfooter{Presents the missing method of Okasaki's red-black trees.}   % 'preprint' option specified.

\title{Deletion: The Curse of the Red-Black Tree}
\subtitle{Functional Pearl}

\authorinfo{Kimball Germane\and Matt Might}
           {University of Utah}
           %{Email2/3}

\maketitle

\begin{abstract}
This is the text of the abstract.
\end{abstract}

\category{CR-number}{subcategory}{third-level}

\terms
term1, term2

\keywords
keyword1, keyword2

\section{Introduction}

When looking for a data structure to back a functional implementation of sets, red-black trees--a type of balanced tree--are a natural choice. Common set operations, such as membership testing and persistent addition map naturally to the native operations of the backing store. And, speaking of maps, minor modifications can turn a set membership test into a map lookup operation and set addition into map extension. Used in this way, red-black trees are efficient, persistent, and still leave us wanting.

To see why, let's briefly review what makes red-black trees so special. A red-black tree is a binary tree in which each node is colored red or black, and which satisfies the invariants that
\begin{enumerate}
\item every red node has two black children, and
\item every path from the root to a leaf\footnote{For our purposes, leaf nodes do not contain data and are always colored black.} node contains the same number of black nodes.
\end{enumerate}
These conditions guarantee that the longest path from root to leaf can be no more than twice the shortest (the only difference being individual red nodes interspersed along the way), and so the worst-case penalty for a tree search is a reasonable constant factor.

Okasaki \cite{okasaki1999functional} made functional red-black trees accessible by presenting a clear method for element insertion. In doing so, he overcame one deficiency and exposed another: the delete operation. Multiple strategies have been developed to offer the delete operation, but each has its own weakness.

Suppose we have a basic implementation of a red-black tree in a language that supports variants and pattern matching. Following Okasaki \cite{okasaki1999functional}, such an implementation might look like this:

\begin{verbatim}
data Color = R | B
data Tree a = E | T Color (Tree a) a (Tree a)

type Set a = Tree a

empty :: Set a
empty = E

member :: Ord a => a -> Set a -> Bool
member x E = False
member x (T _ l y r) | x <  y = member x l
                     | x == y = True
                     | x >  y = member x r 

insert :: (Ord a) => a -> Set a -> Set a
insert x s = makeBlack (ins s)
  where ins E = T R E x E
        ins (T color l y r) | x <  y = balance color (ins l) y r
                            | x == y = T color a y b
                            | x >  y = balance color l y (ins r)
        makeBlack (T _ l y r) = T B l y r
\end{verbatim}
Once the need for balancing is properly motivated and intuition described, the [novelty,bulk,workhorse,?] of the algorithm lies in the \texttt{balance} operation. The punchline of Okasaki's exposition is this simple, elegant implementation.
\begin{verbatim}
balance B (T R (T R a x b) y c) z d
     || B (T R a x (T R b y c)) z d
     || B a x (T R (T R b y c) z d)
     || B a x (T R b y (T R c z d)) = T R (T B a x b) y (T B c z d)
balance color a x b = T color a x b
\end{verbatim}

Red-black trees have a local [more like recursive] invariant which induces a global property.

\section{Deletion}

To support this operation, he suggests the approach of marking nodes as deleted instead of removing them from the tree outright \cite[p. 50]{okasaki1996purely}. This approach trades a rebalancing operation at removal for a global tree rebuild at time indeterminate ( and preserves time complexity only by amortizing the cost). This approach has other disadvantages. First, it contaminates the implementation: every operation needs to be taught about the deletion field and how to handle nodes so marked [, and the global rebuild condition must be tracked]. [Show example if need content.] Second, retaining references to ``deleted'' node data prevents it from being garbage-collected. [Elaborate if need content.]

To support deletion using this strategy, we first introduce a flag in the datatype indicating whether the element should be considered present or not, and teach the operations on that data type about the flag.
\begin{verbatim}
data Color = R | B
data Tree a = E | T Color Bool (Tree a) a (Tree a)

type Set a = Tree a

empty :: Set a
empty = E

member :: Ord a => a -> Set a -> Bool
member x E = False
member x (T _ f l y r) | x <  y = member x l
                       | x == y = f
                       | x >  y = member x r 

insert :: (Ord a) => a -> Set a -> Set a
insert x s = makeBlack (ins s)
  where ins E = T R True E x E
        ins (T color flag a y b) | x <  y = balance color flag (ins a) y b
                                 | x == y = T color True a y b
                                 | x >  y = balance color flag a y (ins b)
        makeBlack (T _ f a y b) = T B flag a y b
\end{verbatim}
We omit the corresponding changes to \texttt{balance}. With that in place, a first pass at a \cite{delete} operation can be made:
\begin{verbatim}
delete :: Ord a -> a -> Set a -> Set a
delete x E = E
delete x (T color flag a y b) | x <  y = T color flag (delete x a) y b
                              | x == y = T color False a y b
                              | x >  y = T color flag a y (delete x b)
\end{verbatim}
The implementation is certainly correct, but it removes the time complexity guarantee that is worth the conceptual complexity. In order to preserve that, we introduce the necessary bookkeeping to trigger a global rebuild at the proper time.
\begin{verbatim}
data Color = R | B
data Tree a = E | T Color Bool Int Int (Tree a) a (Tree a)
...
\end{verbatim}
Once the need for balancing is properly motivated and intuition described, the [novelty,bulk,workhorse,?] of the algorithm lies in the \texttt{balance} operation. The punchline of Okasaki's exposition is this simple, elegant implementation.
\begin{verbatim}
balance B (T R (T R a x b) y c) z d
     || B (T R a x (T R b y c)) z d
     || B a x (T R (T R b y c) z d)
     || B a x (T R b y (T R c z d)) = T R (T B a x b) y (T B c z d)
balance color a x b = T color a x b
\end{verbatim}

The appropriate choice of node type for a red-black tree allows it to be used for a variety of applications. (Yuck.) A singleton allows it to back mathematical sets with insert and member? operations. A pair allows it to implement dictionaries with set and lookup operations. etc. No choice of node can compensate for the lack of a remove operation.

Removal of [Okasaki] nodes from trees can be accomplished by marking a node as deleted and deferring the actual removal to a batch removal performed when deleted nodes begin to outnumber the others. This operation gives even lower than amortized logarithmic time complexity and doesn't interfere with the complexity of other tree operations.

What is the argument for a removal operation with immediate complexity of O(log n)?
Okasaki's thesis, page 50 (as numbered), par. 3: this mentions the cost of marking the node as deleted, but doesn't factor it into the amortized cost, correct? If we have n nodes and "delete" n/2, that takes (n log n)/2 operations. The rebuild takes n operations. So the amortized complexity is [(n log n)/2 + n]/(n/2)=log n + 1/2, or log n. So, the complexity is the same, but there is a constant factor. What happens if we add and remove the element multiple times. The addition has an immediate complexity and so is taken care of. The deletion has an amortized complexity, but say each deleted node was added and deleted k times. Then more deletes are happening over which the n/2 cost is spread, so it's actually better.

An immediate delete localizes the (conceptual /and/ time) complexity of the data structure. (Conceptually, because a counter needs to be kept in the other case, unless you want to incur an O(n) operation every time you want to delete.)

A red-black tree must satisfy two invariants:



The first invariant ensures that at most one red node can separate an otherwise parent and child. Coupled with the second invariant, we are guaranteed that the longest path from the root to an empty node is at most twice as long as the shortest path, with the difference made up by interspersed red nodes.

There are x operations generally defined for red-black trees.

Red-black trees are typically used as the backing store for finite subsets of 
a totally-ordered set or finite maps with a totally-ordered domain.

Emphasize that we would like to localize the complexity.

If we mark nodes as deleted, every operation must know about deleted nodes.
In order to add the delete operation [in this way], we must modify every 
other operation.

THIS IS BIG: real research is going to come from a question in the form of
"prove or disprove". Being told something is true (or good) and asked to 
justify it is going to lead to disintegrity.

First, the implementation of a simple binary tree.

data Tree a = Empty | Node a (Tree a) (Tree a)

insert :: (Ord a) => Tree a -> a -> Tree a
insert Empty x = Node x Empty Empty
insert (Node y l r) x = | x < y     -> Node y (insert l x) r
                        | otherwise -> Node y l (insert r x)

count :: Tree a -> Int
count Empty = 0
count (Node \_ l r) = 1 + (count l) + (count r)

member :: (Ord a) => Tree a -> a -> Boolean
member Empty \_ = False
member (Node y l r) x = x < y     -> member l x
                        x > y     -> member r x
                        otherwise -> True

Deletion in a binary tree is fairly straightforward.

delete :: (Ord a) => Tree a -> a -> Tree a
delete Empty \_ = Empty
delete (Node x l Empty) x = l
delete (Node x Empty r) x = r
delete (Node x l (Node
delete (Node y l r) x = x < y     -> Node y (delete l x) r
                        x > y     -> Node y l (delete r x)
                        otherwise ->

data Color = Red | Black
data Tree a = Empty | Node Color a (Tree a) (Tree a)

enforcing invariants with types leads to Byz

\section{Conclusion}
It is true that genuine deletion is complex, but its complexity is fairly localized. Aside from the \texttt{delete} function proper, it requires the extension of the \texttt{Color} datatype to support two more atomic variants and a few helper functions to support color arithmetic. [It's a small price to pay.] In exchange, we receive O(log n) direct time complexity without any additional constant factor above the original implementation.

\appendix
\section{Appendix Title}

This is the text of the appendix, if you need one.

\acks

Acknowledgments, if needed.

% We recommend abbrvnat bibliography style.

\bibliographystyle{abbrvnat}
\bibliography{red-black-pearl}

% The bibliography should be embedded for final submission.

\begin{thebibliography}{}
\softraggedright

\bibitem[Smith et~al.(2009)Smith, Jones]{smith02}
P. Q. Smith, and X. Y. Jones. ...reference text...

\end{thebibliography}

\end{document}







